{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f374f4fb",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models\n",
    "\n",
    "In the last section we looked at the forward diffusion process of generating noise from a clean image. In this section we will look at the reverse process of generating data based on noise. Instead of images we will start with a generated 2D dataset.\n",
    "\n",
    "## Backgorund - Reverse Process\n",
    "\n",
    "The purpose of the reverse process $p$ is to approximate the previous step $x_{t-1}$ in the diffusion chain based on a sample $x_t$. In practice, this approximation $p(x_{t-1}|x_t)$ must be done without the knowledge of $x_0$.\n",
    "\n",
    "A parametrizable prediction model with parameters $\\theta$ is used to estimate $p_\\theta(x_{t-1}|x_t)$.\n",
    "\n",
    "The reverse process will also be (approximately) gaussian if the diffusion steps are small enough:\n",
    "\n",
    "$$\n",
    "p_\\theta({x}_{0:T}) = p({x}_T) \\prod^T_{t=1} p_\\theta({x}_{t-1} \\vert {x}_t) \\quad\n",
    "p_\\theta({x}_{t-1} \\vert {x}_t) := \\mathcal{N}({x}_{t-1}; \\boldsymbol{\\mu}_\\theta({x}_t, t), \\boldsymbol{\\Sigma}_\\theta({x}_t, t))\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "In many works, it is assumed that the variance of this distribution should not depend strongly on $x_0$ or $x_t$, but rather on the stage of the diffusion process $t$. This can be observed in the true distribution $q(x_{t-1}|x_t, x_0)$, where the variance of the distribution equals $\\tilde{\\beta}_t$.\n",
    "\n",
    "### Parameterizing $\\mu_\\theta$\n",
    "There are at least 3 ways of parameterizing the mean of the reverse step distribution $p_\\theta(x_{t-1}|x_t)$:\n",
    "1. Directly (a neural network will **estimate $\\mu_\\theta$**)\n",
    "$$\\mu_\\theta = \\mu_\\theta(x_t,t)$$\n",
    "2. Via $x_0$ (a neural network will **estimate $x_0$**)\n",
    "$$\\tilde{\\mu}_\\theta = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar{\\alpha}_t}x_{0, \\theta}(x_t,t) + \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t $$\n",
    "\n",
    "3. Via noise $\\epsilon$ subtraction from $x_t$ (a neural network will **estimate $\\epsilon$**)\n",
    "$$x_t=\\sqrt{\\bar{\\alpha}_t}\\hat{x}_0 + \\epsilon_\\theta(x_t,t)\\sqrt{1-\\bar{\\alpha}_t}$$\n",
    "$$\\hat{x}_0=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}x_t - \\epsilon_\\theta(x_t,t)\\sqrt{\\frac{1}{\\bar{\\alpha}_t}-1}$$\n",
    "\n",
    "\n",
    "Approach 3 approximating the normal noise $\\epsilon_\\theta$ is used most widely. For the diffusion denoising process of images, U-Nets are often used. The U-Net architecture is a convolutional neural network that was introduced for image segmentation. It is called U-Net because its architecture looks U-shaped. The input gets downsampled and then upsampled again to the output. Additionally layers with the same size on the down and upsampling side are connected with skip connections, keeping important information. An example of a U-Net for estimating $\\epsilon$ is shown in the figure below.\n",
    "\n",
    "<figure>\n",
    "<img src=\"./imgs/U-net.png\" alt=\"U-Net\" width=\"500\"/>\n",
    "<figcaption>U-Net Architecture with ResNet blocks (from: https://cvpr2022-tutorial-diffusion-models.github.io/)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca176b4b",
   "metadata": {},
   "source": [
    "## Loading necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"diffusion\")\n",
    "using Plots\n",
    "using Flux\n",
    "using BSON\n",
    "using JSON\n",
    "using StatsBase\n",
    "using Printf\n",
    "using LaTeXStrings\n",
    "using Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e22fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "include(\"./DenoisingDiffusion/src/DenoisingDiffusion.jl\")\n",
    "using .DenoisingDiffusion\n",
    "using .DenoisingDiffusion: train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "includet(\"./DenoisingDiffusion/common/datasets.jl\");\n",
    "includet(\"./DenoisingDiffusion/common/utilities.jl\");\n",
    "directory = joinpath(\"outputs\", \"2d_\" * Dates.format(now(), \"yyyymmdd_HHMM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b8e84c",
   "metadata": {},
   "source": [
    "## Generating the Data\n",
    "\n",
    "First, we generate a noise disturbed 2D Swiss Roll dataset with 10000 samples. The Swiss Roll is a classic dataset with a non-linear structure. The data is generated to be similar to the `make_swiss_roll` function from the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acc6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10_000\n",
    "X = normalize_neg_one_to_one(make_spiral(n_samples))\n",
    "X_val = normalize_neg_one_to_one(make_spiral(floor(Int, 0.1 * n_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X[1, :], X[2, :], alpha=0.5, aspectratio=:equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edb002",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Since we now have our data we can start building our model. Similar to the U-Net from above we want to create a model that can estimate the noise $\\epsilon$ from the data point $x$ for a given time $t$. First we will use a simple feedforward neural network since we only have 2D data:\n",
    "\n",
    "<figure>\n",
    "<img src=\"./imgs/simple_MLP_model.png\" alt=\"simple_MLP_model\" width=\"500\"/>\n",
    "<figcaption>Conditional noise estimation model.</figcaption>\n",
    "</figure>\n",
    "\n",
    "### How can we build a model that takes the data and the time as input and returns the noise?\n",
    "\n",
    "Notice how the model not only has to depend on the data point $x$ but also on the time $t$. This is because the noise $\\epsilon$ is dependent on the time $t$ not only the data point $x$. A good model should therefore be time dependant. However, for efficiency we should share the weights of the model for different times. This can be done by using an embedding vectors for the time $t$ and add them to the output of the layers which are based on the data $x$.\n",
    "\n",
    "We can do this using `Flux.Embedding` or using `SinusoidalPositionEmbedding` from `DenoisingDiffusion.jl`. It creates a matrix where every column as a whole is unique. Each column can then be used as a time embedding for a particular time step. The uniqueness of each column is accomplished by using periodic trigonometric functions for the rows with gradually increasing frequency. See the image below for a visual demonstration.\n",
    "\n",
    "<figure>\n",
    "<img src=\"./imgs/position_encodings.png\" alt=\"position_encodings\" width=\"500\"/>\n",
    "<figcaption>Heatmap demonstrating the sinusodial embedding.</figcaption>\n",
    "</figure>\n",
    "\n",
    "You can try both embedding functions. We will use the latter for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96281dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### settings\n",
    "num_timesteps = 40\n",
    "to_device = cpu\n",
    "num_epochs = 120\n",
    "\n",
    "d_hid = ... # set to reasonable value\n",
    "d_in_out = ... # set to correct value for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalChain(\n",
    "    Parallel(.+, Dense(d_in_out, d_hid), Chain(SinusoidalPositionEmbedding(num_timesteps, d_hid), Dense(d_hid, d_hid))),\n",
    "    swish,\n",
    "    Parallel(.+, Dense(d_hid, d_hid), Chain(SinusoidalPositionEmbedding(num_timesteps, d_hid), Dense(d_hid, d_hid))),\n",
    "    swish,\n",
    "    Parallel(.+, Dense(d_hid, d_hid), Chain(SinusoidalPositionEmbedding(num_timesteps, d_hid), Dense(d_hid, d_hid))),\n",
    "    swish,\n",
    "    Dense(d_hid, d_in_out),\n",
    ")\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e2817",
   "metadata": {},
   "source": [
    "Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31985fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test forward pass by getting some samples from our training data\n",
    "n_batch = 10 \n",
    "X_t = X[:, 1:n_batch]\n",
    "X_t = to_device(X_t)\n",
    "println(size(X_t))\n",
    "# make time steps \n",
    "timesteps = rand(1:num_timesteps, size(X_t, n_batch)) |> to_device\n",
    "# test forward pass\n",
    "X_t_hat = model(X_t, timesteps)\n",
    "# the output should be the same shape as the input\n",
    "println(size(X_t_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d953e",
   "metadata": {},
   "source": [
    "### Let's define our schedule again \n",
    "This is similar to the schedule we used in the previous section. We use the same schedule for the forward and reverse process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "βs = linear_beta_schedule(num_timesteps, 8e-6, 9e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078053e",
   "metadata": {},
   "source": [
    "Based on the schedule and our noise prediction model we can now define a `GaussianDiffusion` Model. It collects everything to estimates the normal distributions and saves it in a struct for easy access: \n",
    "```julia\n",
    "function GaussianDiffusion(V::DataType, βs::AbstractVector, data_shape::NTuple, denoise_fn)\n",
    "    αs = 1 .- βs\n",
    "    α_cumprods = cumprod(αs)\n",
    "    α_cumprod_prevs = [1, (α_cumprods[1:end-1])...]\n",
    "\n",
    "    sqrt_α_cumprods = sqrt.(α_cumprods)\n",
    "    sqrt_one_minus_α_cumprods = sqrt.(1 .- α_cumprods)\n",
    "    sqrt_recip_α_cumprods = 1 ./ sqrt.(α_cumprods)\n",
    "    sqrt_recip_α_cumprods_minus_one = sqrt.(1 ./ α_cumprods .- 1)\n",
    "\n",
    "    posterior_variance = βs .* (1 .- α_cumprod_prevs) ./ (1 .- α_cumprods)\n",
    "    posterior_log_variance_clipped = log.(max.(posterior_variance, 1e-20))\n",
    "\n",
    "    posterior_mean_coef1 = βs .* sqrt.(α_cumprod_prevs) ./ (1 .- α_cumprods)\n",
    "    posterior_mean_coef2 = (1 .- α_cumprod_prevs) .* sqrt.(αs) ./ (1 .- α_cumprods)\n",
    "\n",
    "    GaussianDiffusion{V}(\n",
    "        length(βs),\n",
    "        data_shape,\n",
    "        denoise_fn,\n",
    "        βs,\n",
    "        αs,\n",
    "        α_cumprods,\n",
    "        α_cumprod_prevs,\n",
    "        sqrt_α_cumprods,\n",
    "        sqrt_one_minus_α_cumprods,\n",
    "        sqrt_recip_α_cumprods,\n",
    "        sqrt_recip_α_cumprods_minus_one,\n",
    "        posterior_variance,\n",
    "        posterior_log_variance_clipped,\n",
    "        posterior_mean_coef1,\n",
    "        posterior_mean_coef2\n",
    "    )\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = GaussianDiffusion(Vector{Float32}, βs, (2,), model)\n",
    "diffusion = diffusion |> to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453005ee",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Now we have everything to train our model, except for the loss we want to minimize. In the last section we discussed the forward process $q(x_t|x_{t-1})$ and now the reverse process $p_{\\theta}(x_{t-1}|x_t)$. Ideally if we start with $x_{t-1}$ to generate $x_t$ using $q(x_t|x_{t-1})$ and then use $x_t$ to generate $x_{t-1}$ using $p_{\\theta}(x_{t-1}|x_t)$ we should get the same $x_{t-1}$ as we started with. Hence the forward the reverse process should cancel each other out. \n",
    "\n",
    "The paper by [Ho et al.](https://arxiv.org/abs/2006.11239) which intorduced DDPM, showed that they could successfully train the model using a simple loss of the form: \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathbb{E} [|| \\epsilon - \\epsilon_{\\theta} ||^2]\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is the true noise and $\\epsilon_{\\theta}$ is the predicted noise. We can use the `Flux.mse` loss function to minimize the difference between the true noise and the predicted noise. Additionally we  use the `ADAM` optimizer to minimize this loss. We will train the model for 100 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb1fbb",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "Now let's define a function which takes the model, the data and the mse loss function and uses these to sample noised images, denoise them and calculate the loss. \n",
    "\n",
    "1. Generate the time steps for the schedule\n",
    "2. Sample the noise for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = X_t\n",
    "timesteps = # Get random time steps for each batch in the correct range using the rand function\n",
    "noise = randn(eltype(eltype(diffusion)), size(x_start)) |> to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c6ef8",
   "metadata": {},
   "source": [
    "3. Add noise to the data:\n",
    "\n",
    "    To noise the data we can use the `q_sample` from `GaussianDiffusion.jl`. The function is defined as follows:\n",
    "    ```julia\n",
    "    function q_sample(\n",
    "        diffusion::GaussianDiffusion, \n",
    "        x_start::AbstractArray, \n",
    "        timesteps::AbstractVector{Int}, \n",
    "        noise::AbstractArray\n",
    "        )\n",
    "        coeff1 = _extract(diffusion.sqrt_α_cumprods, timesteps, size(x_start))\n",
    "        coeff2 = _extract(diffusion.sqrt_one_minus_α_cumprods, timesteps, size(x_start))\n",
    "        coeff1 .* x_start + coeff2 .* noise\n",
    "    end\n",
    "    ```\n",
    "\n",
    "    Using X_t from above let's call it and see what it returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ... # sample from the diffusion model using q_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82fc15",
   "metadata": {},
   "source": [
    "4. Estimate the noise from the input data:\n",
    "\n",
    "    Therefore we call our model to estimate the noise of the noised data using the `denoise_fn` from the `GaussianDiffusion` struct: `diffusion.denoise_fn(x, timesteps)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out =  ... # get the output of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdddcb0",
   "metadata": {},
   "source": [
    "This does not jet the right function to estimate the noise from the data, since we have to train our model first. However, now you have all the necessary steps to do the last step: \n",
    "\n",
    "5. Calculate the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dab7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = Flux.mse;\n",
    "est_loss = ... # calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080bd3ef",
   "metadata": {},
   "source": [
    "Finally let's put all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b25bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function p_losses(diffusion::GaussianDiffusion, loss, x_start::AbstractArray{T,N}; to_device=cpu) where {T,N}\n",
    "    # estimate and return the loss based on the steps above \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines us a function that we can use to calculate the loss using the Flux training loop\n",
    "loss(diffusion, x::AbstractArray) = p_losses(diffusion, loss_type, x; to_device=to_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the loss with the X_t samples from the previous test:\n",
    "loss(diffusion, X_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee62919",
   "metadata": {},
   "source": [
    "Define the data loaders and test our initial model using the validation data and the loss function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa63339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and val data loaders\n",
    "train_data = Flux.DataLoader(X |> to_device; batchsize=32, shuffle=true);\n",
    "val_data = Flux.DataLoader(X_val |> to_device; batchsize=32, shuffle=false);\n",
    "opt = Adam(0.001);\n",
    "\n",
    "# Calculating initial loss\n",
    "val_loss = 0.0\n",
    "for x in val_data\n",
    "    global val_loss\n",
    "    val_loss += loss(diffusion, x)\n",
    "end\n",
    "val_loss /= length(val_data)\n",
    "@printf(\"\\nval loss: %.5f\\n\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b203b",
   "metadata": {},
   "source": [
    "### Start the Training:\n",
    "\n",
    "The Training algorithm is as follows:\n",
    "\n",
    "Repeat for each epoch:  \n",
    "- Sample data: $x_0 \\sim q(x_0)$   \n",
    "- Sample time: $t \\sim \\mathcal{U}(1, ... ,T)$  \n",
    "- Sample noise: $\\epsilon \\sim \\mathcal{N}(0,I)$  \n",
    "- Generate $x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon$  \n",
    "- Estimate $\\epsilon_{\\theta} \\sim p_{\\theta}(x_{t-1}|x_t)$  \n",
    "- Compute the loss: $\\mathcal{L} = \\mathbb{E} [|| \\epsilon - \\epsilon_{\\theta} ||^2]$  \n",
    "- Update the model parameters using the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time_ns()\n",
    "opt_state = Flux.setup(opt, diffusion)\n",
    "history = train!(loss, diffusion, train_data, opt_state, val_data; num_epochs=num_epochs)\n",
    "end_time = time_ns() - start_time\n",
    "\n",
    "@printf \"time taken: %.2fs\\n\" end_time / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb46f0",
   "metadata": {},
   "source": [
    "### Plot the Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3536d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = diffusion |> cpu\n",
    "\n",
    "canvas_train = plot(\n",
    "    1:length(history[\"mean_batch_loss\"]), history[\"mean_batch_loss\"], label=\"mean batch loss\",\n",
    "    xlabel=\"epoch\",\n",
    "    ylabel=\"loss\",\n",
    "    legend=:right, # :best, :right\n",
    "    ylims=(0, Inf),\n",
    ")\n",
    "plot!(canvas_train, 1:length(history[\"val_loss\"]), history[\"val_loss\"], label=\"validation loss\")\n",
    "display(canvas_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4241cf",
   "metadata": {},
   "source": [
    "### Plot the Results\n",
    "\n",
    "We can predict the noise $\\epsilon_{\\theta}$ using the trained model $\\epsilon_\\theta(x_t,t)$ simply like this:\n",
    "```julia\n",
    "noise = diffusion.denoise_fn(x, timesteps)\n",
    "```\n",
    "After that we can predict the start point using the predicted noise (this is done using the `denoise` function from `DenoisingDiffusion.jl`):\n",
    "$$\\hat{x}_0=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}x_t - \\epsilon_\\theta(x_t,t)\\sqrt{\\frac{1}{\\bar{\\alpha}_t}-1}$$\n",
    "\n",
    "Then we can estimate the mean $\\tilde{\\mu}_t$ and standard deviation $\\tilde{\\beta}_t$ of the posterior distribution $p_\\theta({x}_{t-1} \\vert {x}_t)$:\n",
    "$$\\tilde{\\mu}_t(x_t, \\hat{x}_0) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar{\\alpha}_t}\\hat{x}_0 + \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t$$\n",
    "$$\\tilde{\\beta}_t = \\beta_t\\frac{(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}$$\n",
    "\n",
    "This estimation is done using the `q_posterior_mean_variance` function from `DenoisingDiffusion.jl`. Lastly we call the `p_sample` function to sample from the posterior distribution $p_\\theta({x}_{t-1} \\vert {x}_t)$ to get $x_{t-1}$ for the reverse process:\n",
    "$$x_{t-1} = \\tilde{\\mu}_t(x_t, \\hat{x}_0)+\\tilde{\\beta}_t z \\quad \\text{where} \\quad z \\sim \\mathcal{N}(0, I)$$\n",
    "\n",
    "> Note that I used $z$ here since it is a sample from the standard normal distribution and should not be confused with the predicted noise $\\epsilon_{\\theta}$. Nevertheless, the predicted sample $x_{t-1}$ is a sample from the posterior distribution:\n",
    ">$$ p_\\theta({x}_{t-1} \\vert {x}_t) := \\mathcal{N}({x}_{t-1}; \\boldsymbol{\\mu}_t(x_t, \\hat{x}_0), \\tilde{\\beta}_t)$$\n",
    "\n",
    "To generate samples starting from noise we use these steps several times as shown in the following:\n",
    "\n",
    "Repeat for each sample:  \n",
    "- Sample noise: $\\epsilon \\sim \\mathcal{N}(0,I)$  \n",
    "- Repeat for each time step $t$ in reverse order:  \n",
    "    - Predict the noise: $\\epsilon_{\\theta}(x_t, t)$\n",
    "    - Predict the start point: $\\hat{x}_0$\n",
    "    - Estimate the mean and standard deviation of the posterior distribution: $\\tilde{\\mu}_t(x_t, \\hat{x}_0)$ and $\\tilde{\\beta}_t$\n",
    "    - Sample from the posterior distribution: $x_{t-1} = \\tilde{\\mu}_t(x_t, \\hat{x}_0)+\\tilde{\\beta}_t z$\n",
    "    - Set $x_t = x_{t-1}$\n",
    "- Return the final generated sample $x_t$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27363f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate new samples and denoise it to the first time step.\n",
    "function p_sample_loop(diffusion::GaussianDiffusion, shape::NTuple; clip_denoised::Bool=true, to_device=cpu)\n",
    "    T = eltype(eltype(diffusion))\n",
    "    x = randn(T, shape) |> to_device\n",
    "    for t in diffusion.num_timesteps:-1:1\n",
    "        timesteps = fill(t, shape[end]) |> to_device\n",
    "        noise = randn(T, size(x)) |> to_device\n",
    "        x, x_start = p_sample(diffusion, x, timesteps, noise; clip_denoised=clip_denoised, add_noise=(t != 1))\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "function p_sample_loop(diffusion::GaussianDiffusion, batch_size::Int; options...)\n",
    "    p_sample_loop(diffusion, (diffusion.data_shape..., batch_size); options...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a08837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = p_sample_loop(diffusion, 1000)\n",
    "canvas_samples = scatter(X0[1, :], X0[2, :], alpha=0.5, label=\"\",\n",
    "    aspectratio=:equal,\n",
    "    xlims=(-2, 2), ylims=(-2, 2),\n",
    ")\n",
    "display(canvas_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab838a2c",
   "metadata": {},
   "source": [
    "## Visualize the reverse process\n",
    "Note that `p_sample` can additionally return the estimated start sample at each step $\\hat{x}_0$. So we can plot both the current sample after the performed time steps and the estimated start sample at each time step. \n",
    "\n",
    "First let's define a function which samples the whole reverse process for a given sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new samples and denoise them to the first time step. Return all samples where the last dimension is time.\n",
    "function p_sample_loop_all(diffusion::GaussianDiffusion, shape::NTuple; clip_denoised::Bool=true, to_device=cpu)\n",
    "    T = eltype(eltype(diffusion))\n",
    "    x = randn(T, shape) |> to_device\n",
    "    x_all = Array{T}(undef, size(x)..., 0) |> to_device\n",
    "    x_start_all = Array{T}(undef, size(x)..., 0) |> to_device\n",
    "    tdim = ndims(x_all)\n",
    "    for t in diffusion.num_timesteps:-1:1\n",
    "        timesteps = fill(t, shape[end]) |> to_device\n",
    "        noise = randn(T, size(x)) |> to_device\n",
    "        x, x_start = p_sample(diffusion, x, timesteps, noise; clip_denoised=clip_denoised, add_noise=(t != 1))\n",
    "        x_all = cat(x_all, x, dims=tdim)\n",
    "        x_start_all = cat(x_start_all, x_start, dims=tdim)\n",
    "    end\n",
    "    x_all, x_start_all\n",
    "end\n",
    "\n",
    "function p_sample_loop_all(diffusion::GaussianDiffusion, batch_size::Int=16; options...)\n",
    "    p_sample_loop_all(diffusion, (diffusion.data_shape..., batch_size); options...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796677f",
   "metadata": {},
   "source": [
    "Note that `size(x)...` is used to get the size of the data point $x$ not as a tuple but as separate arguments. For Example, if x is a 2D array with size (3, 4), size(x)... would be equivalent to 3, 4. In function arguments it is used to indicate that the function can take any number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc422db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, X0s = p_sample_loop_all(diffusion, 1000);\n",
    "anim_denoise = @animate for i ∈ 1:(num_timesteps+10)\n",
    "    i = i > num_timesteps ? num_timesteps : i\n",
    "    p1 = scatter(Xs[1, :, i], Xs[2, :, i],\n",
    "        alpha=0.5,\n",
    "        title=L\"${x}_t$\",\n",
    "        label=\"\",\n",
    "        aspectratio=:equal,\n",
    "        xlims=(-2, 2), ylims=(-2, 2),\n",
    "        figsize=(400, 400),\n",
    "    )\n",
    "    p2 = scatter(X0s[1, :, i], X0s[2, :, i],\n",
    "        alpha=0.5,\n",
    "        title=L\"$\\hat{x}_0$\",\n",
    "        label=\"\",\n",
    "        aspectratio=:equal,\n",
    "        xlims=(-2, 2), ylims=(-2, 2),\n",
    "        figsize=(400, 400),\n",
    "    )\n",
    "    plot(p1, p2, plot_title=\"i=$i\")\n",
    "end\n",
    "directory = \"diffusion\"\n",
    "gif(anim_denoise, joinpath(directory, \"reverse_x0.gif\"), fps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
